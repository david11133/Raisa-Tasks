# Azure Blob Storage Data Processing Project

## Overview

This project involves processing data stored in Azure Blob Storage, focusing on several key tasks aimed at maximizing efficiency and accuracy. The primary objectives are to load input data, perform various transformations, and save the results back to Azure Blob Storage.

## Tasks

### Task Overview

1. **Task 0**: Load the data from Azure Blob Storage.
2. **Task 1**: Create a DataFrame for wells.
3. **Task 2**: Validate the `WellGroupCode` column.
4. **Task 3**: Maximize the return on investment.
5. **Final Task**: Upload the output and code back to Azure Blob Storage.

### Additional Requirements

- Ensure your code is well-structured and commented for clarity.
- Focus on optimizing execution time and understanding the time complexity of your code.
- Note: Files cannot be saved to Blob Storage after the submission date, so manage your time wisely.
- Submit a single CSV file with the output and a single Python file containing all your code.

## Getting Started

### Prerequisites

- Python 3.x
- Required libraries: `pandas`, `azure-storage-blob`, etc. (list any other libraries you used)

### Installation

 Clone this repository:
   ```bash
   git clone https://github.com/david11133/Raisa-Tasks
   cd Raisa-Tasks
   ```

### Usage

1. Update the Azure Blob Storage connection details in the code.
2. Run the Python script:
   ```bash
   python main.py
   ```
3. The output CSV will be saved to Azure Blob Storage as specified.

## Conclusion

This project highlights the importance of data handling and transformation in cloud environments. Your feedback is welcome!

## License

This project is licensed under the MIT License. See the LICENSE file for details.
